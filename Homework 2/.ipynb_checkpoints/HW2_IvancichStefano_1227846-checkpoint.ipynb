{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Done:**\n",
    " - ...\n",
    "\n",
    "\n",
    "**Doing:**\n",
    " - 1 pt: implement and test (convolutional) autoencoder, reporting the trend of reconstruction loss and some examples of image reconstruction\n",
    " - 1 pt: explore advanced optimizers and regularization methods\n",
    " - 1 pt: optimize hyperparameters using grid/random search and cross-validation\n",
    " - 1 pt: explore the latent space structure (e.g., PCA, t-SNE) and generate new samples from latent codes\n",
    " - 1 pt: implement and test denoising (convolutional) autoencoder\n",
    " - 2 pt: implement variational (convolutional) autoencoder or GAN\n",
    " \n",
    "**Todo:**\n",
    "\n",
    "- 1 pt: fine-tune the (convolutional) autoencoder using a supervised classification task (you can compare classification accuracy and learning speed with results achieved in homework 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Download the data and create dataset\n",
    "data_dir = 'dataset'\n",
    "# With these commands the train and test datasets, respectively, are downloaded \n",
    "# automatically and stored in the local \"data_dir\" directory.\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot some sample\n",
    "fig, axs = plt.subplots(5, 5, figsize=(8,8))\n",
    "for ax in axs.flatten():\n",
    "    # random.choice allows to randomly sample from a list-like object (basically anything that can be accessed with an index, like our dataset)\n",
    "    img, label = random.choice(train_dataset)\n",
    "    ax.imshow(np.array(img), cmap='gist_gray')\n",
    "    ax.set_title('Label: %d' % label)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) Dataset Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# In this case the train_transform and test_transform are the same, but we keep them separate for potential future updates\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Set the train transform\n",
    "train_dataset.transform = train_transform\n",
    "# Set the test transform\n",
    "test_dataset.transform = test_transform\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class noise(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        noise_factor=0.1*3\n",
    "        noisy_img = image + noise_factor * torch.randn(image.shape)\n",
    "        #clip the image\n",
    "        noisy_img = np.clip(noisy_img, 0., 1.)\n",
    "\n",
    "        return (image,noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    noise(),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    noise(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the train transform\n",
    "train_dataset.transform = train_transform\n",
    "# Set the test transform\n",
    "test_dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define train dataloader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "### Define test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the transformation works\n",
    "for image in test_dataloader:\n",
    "    \n",
    "    plt.imshow(image[0][0][0][0],cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.imshow(image[0][1][0][0],cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    break\n",
    "\n",
    "\n",
    "img=test_dataset[0][0][0].unsqueeze(0).to(device)\n",
    "plt.imshow(img.cpu().squeeze().numpy(),cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "img=test_dataset[0][0][1].unsqueeze(0).to(device)\n",
    "plt.imshow(img.cpu().squeeze().numpy(),cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,dropout=0.5, conv1=8,conv2=16,conv3=32,fc=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(1, conv1, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(p=dropout),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(conv1, conv2, 3, stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(p=dropout),\n",
    "            # Third convolutional layer\n",
    "            nn.Conv2d(conv2, conv3, 3, stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(p=dropout),\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)#dimension 0 is the sample, so we flatten from dimension 1\n",
    "\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(3 * 3 * conv3, fc),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            # Second linear layer\n",
    "            nn.Linear(fc, encoded_space_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.encoder_cnn(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # # Apply linear layers\n",
    "        x = self.encoder_lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoded_space_dim,dropout=0.5, conv1=8,conv2=16,conv3=32,fc=64):\n",
    "        super().__init__()\n",
    "\n",
    "        ### Linear section\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(encoded_space_dim, fc),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            # Second linear layer\n",
    "            nn.Linear(fc, 3 * 3 * conv3),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=dropout),\n",
    "        )\n",
    "\n",
    "        ### Unflatten\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(conv3, 3, 3))\n",
    "\n",
    "        ### Convolutional section\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            # First transposed convolution\n",
    "            nn.ConvTranspose2d(conv3, conv2, 3, stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(p=dropout),\n",
    "            # Second transposed convolution\n",
    "            nn.ConvTranspose2d(conv2, conv1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout2d(p=dropout),\n",
    "            # Third transposed convolution\n",
    "            nn.ConvTranspose2d(conv1, 1, 3, stride=2, padding=1, output_padding=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply linear layers\n",
    "        x = self.decoder_lin(x)\n",
    "        # Unflatten\n",
    "        x = self.unflatten(x)\n",
    "        # Apply transposed convolutions\n",
    "        x = self.decoder_conv(x)\n",
    "        # Apply a sigmoid to force the output to be between 0 and 1 (valid pixel values)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer,noise=False):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        \n",
    "        image= image_batch[0].to(device)\n",
    "        \n",
    "        noisy=image    \n",
    "        if noise: \n",
    "            noisy=image_batch[1].to(device)\n",
    "\n",
    "        # Encode data\n",
    "        encoded_data = encoder(noisy)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image)\n",
    "        \n",
    "        \"\"\"OLD\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "        \n",
    "        # Encode data\n",
    "        #encoded_data = encoder(image_batch)\n",
    "        \n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image_batch)\"\"\"\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        #print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder, decoder, device, dataloader, loss_fn,noise=False):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for image_batch, _ in dataloader:\n",
    "            image= image_batch[0].to(device)\n",
    "        \n",
    "            noisy=image\n",
    "            \n",
    "            if noise: \n",
    "                noisy=image_batch[1].to(device)\n",
    "                \n",
    "            # Encode data\n",
    "            encoded_data = encoder(noisy)\n",
    "            \n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image.cpu())\n",
    "            \n",
    "            \n",
    "            \"\"\"OLD\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            \n",
    "            \n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\"\"\"\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "def training_cycle(num_epochs,early_stopping,encoder,decoder,loss_fn,optim,train_dataloader,device,test_dataset,noise=False):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "\n",
    "    max_early=float(\"-inf\")\n",
    "    idx_early=-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('\\t EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "\n",
    "        ### Training (use the training function)\n",
    "        train_loss=train_epoch(\n",
    "            encoder=encoder, \n",
    "            decoder=decoder, \n",
    "            device=device, \n",
    "            dataloader=train_dataloader, \n",
    "            loss_fn=loss_fn, \n",
    "            optimizer=optim)\n",
    "        train_loss_log.append(train_loss)\n",
    "        print('\\t TRAIN - EPOCH %d/%d - loss: %f' % (epoch + 1, num_epochs, train_loss))\n",
    "\n",
    "        ### Validation  (use the testing function)\n",
    "        val_loss = test_epoch(\n",
    "            encoder=encoder, \n",
    "            decoder=decoder, \n",
    "            device=device, \n",
    "            dataloader=test_dataloader, \n",
    "            loss_fn=loss_fn)\n",
    "        val_loss_log.append(val_loss)\n",
    "        print('\\t VALIDATION - EPOCH %d/%d - loss: %f' % (epoch + 1, num_epochs, val_loss))\n",
    "\n",
    "        ### Plot progress\n",
    "        # Get the output of a specific image (the test image at index 0 in this case)\n",
    "        img = test_dataset[0][0][0].unsqueeze(0).to(device)\n",
    "        if noise: img = test_dataset[0][0][1].unsqueeze(0).to(device)\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            rec_img  = decoder(encoder(img))\n",
    "        # Plot the reconstructed image\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "        axs[0].imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "        axs[0].set_title('Original image')\n",
    "        axs[1].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "        axs[1].set_title('Reconstructed image (EPOCH %d)' % (epoch + 1))\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.1)\n",
    "        # Save figures\n",
    "        os.makedirs('autoencoder_progress_%d_features' % encoded_space_dim, exist_ok=True)\n",
    "        fig.savefig('autoencoder_progress_%d_features/epoch_%d.jpg' % (encoded_space_dim, epoch + 1))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Save network parameters\n",
    "        torch.save(encoder.state_dict(), 'encoder_params.pth')\n",
    "        torch.save(decoder.state_dict(), 'decoder_params.pth')\n",
    "        torch.save(optim.state_dict(), 'optim_params.pth')\n",
    "\n",
    "\n",
    "        #Early stopping:\n",
    "        if idx_early==-1:\n",
    "            idx_early=epoch\n",
    "            max_early=val_loss\n",
    "        elif round(float(val_loss),3)<round(float(max_early),3):\n",
    "            idx_early=epoch\n",
    "            max_early=val_loss\n",
    "            \n",
    "        elif epoch-idx_early>=early_stopping:\n",
    "            print(\"STOPPED BY EARLY STOPPYNG\")\n",
    "            break\n",
    "    \n",
    "    return (train_loss_log,val_loss_log)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hyperparams:\n",
    "encoded_space_dim = [2, 4, 128]\n",
    "num_epochs=50\n",
    "early_stopping=5\n",
    "Conv1=[8,16,32,64]\n",
    "Conv2=[8,16,32,64]\n",
    "Conv3=[8,16,32,64]\n",
    "FC=[32,64,128]\n",
    "LR=[1e-2,1e-3,1e-4]\n",
    "L2=[1e-3,1e-4,1e-5]\n",
    "drop=[0,0.25,0.5,0.75]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "space_dim = [2]\n",
    "num_epochs=50\n",
    "early_stopping=5\n",
    "Conv1=[8]\n",
    "Conv2=[16]\n",
    "Conv3=[32]\n",
    "FC=[64]\n",
    "LR=[1e-3]\n",
    "L2=[1e-5]\n",
    "drop=0\n",
    "\n",
    "\n",
    "hyperparams = [space_dim,Conv1,Conv2,Conv3,FC,LR,L2]  \n",
    "\n",
    "iterations=[]\n",
    "import itertools\n",
    "for hyper in itertools.product(*hyperparams):\n",
    "    iterations.append(hyper)\n",
    "print(\"Total Combinations:\",len(iterations))\n",
    "\n",
    "\n",
    "best_hyper=None\n",
    "best_loss=None\n",
    "for i,hyper in enumerate(iterations):\n",
    "    print(\"\\n\\nIteration:\",i,hyper)\n",
    "    encoded_space_dim,conv1,conv2,conv3,fc,lr,l2=hyper\n",
    "    \n",
    "    ### Initialize the two networks\n",
    "    encoder = Encoder(encoded_space_dim=encoded_space_dim,dropout=drop, conv1=conv1,conv2=conv2,conv3=conv3,fc=fc)\n",
    "    decoder = Decoder(encoded_space_dim=encoded_space_dim,dropout=drop, conv1=conv1,conv2=conv2,conv3=conv3,fc=fc)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    ### Define an optimizer (both for the encoder and the decoder!)\n",
    "    params_to_optimize = [\n",
    "        {'params': encoder.parameters()},\n",
    "        {'params': decoder.parameters()}\n",
    "    ]\n",
    "    optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=l2)\n",
    "\n",
    "    # Move both the encoder and the decoder to the selected device\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "    \n",
    "    \n",
    "    #TRAINING CYCLE\n",
    "    train_loss_log,val_loss_log=training_cycle(num_epochs,\n",
    "                                           early_stopping,\n",
    "                                           encoder,\n",
    "                                           decoder,\n",
    "                                           loss_fn,\n",
    "                                           optim,\n",
    "                                           train_dataloader,\n",
    "                                           device,\n",
    "                                           test_dataset)\n",
    "    train_loss=train_loss_log[-1]\n",
    "    val_loss=val_loss_log[-1]\n",
    "    print(\"\\tTrain Loss:\",round(float(train_loss),3),\"\\tVal Loss:\",round(float(val_loss),3))\n",
    "    \n",
    "    if not best_loss or val_loss<best_loss:\n",
    "        best_loss=val_loss\n",
    "        best_hyper=hyper\n",
    "\n",
    "        \n",
    "print(\"\\n\\nBest Model:\",best_hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the best model\n",
    "if best_hyper:\n",
    "    encoded_space_dim,conv1,conv2,conv3,fc,lr,l2=best_hyper\n",
    "    print(\"Training:\",best_hyper)\n",
    "\n",
    "\n",
    "### Initialize the two networks\n",
    "encoder = Encoder(encoded_space_dim=encoded_space_dim,dropout=drop, conv1=conv1,conv2=conv2,conv3=conv3,fc=fc)\n",
    "decoder = Decoder(encoded_space_dim=encoded_space_dim,dropout=drop, conv1=conv1,conv2=conv2,conv3=conv3,fc=fc)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=l2)\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "    \n",
    "    \n",
    "train_loss_log,val_loss_log=training_cycle(num_epochs,\n",
    "                                           early_stopping,\n",
    "                                           encoder,\n",
    "                                           decoder,\n",
    "                                           loss_fn,\n",
    "                                           optim,\n",
    "                                           train_dataloader,\n",
    "                                           device,\n",
    "                                           test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses of the best model\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogy(train_loss_log, label='Train loss')\n",
    "plt.semilogy(val_loss_log, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) Metric Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=train_loss_log[-1]\n",
    "val_loss=val_loss_log[-1]\n",
    "print(\"Train Loss:\\t\",round(float(train_loss),3))\n",
    "print(\"Val Loss:\\t\",round(float(val_loss),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Latent Space Visualization and Sample Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) Latent Space Visualization with T-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network parameters\n",
    "encoder.load_state_dict(torch.load('encoder_params.pth'))\n",
    "decoder.load_state_dict(torch.load('decoder_params.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the encoded representation of the test samples\n",
    "encoded_samples = []\n",
    "labels=[]\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    #encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    #encoded_sample['label'] = label\n",
    "    #encoded_samples.append(encoded_sample)\n",
    "    encoded_samples.append(encoded_img)\n",
    "    labels.append(str(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(encoded_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "#plt.scatter(X_tsne[:,0],X_tsne[:,1],c=labelsint)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.scatter(x=X_tsne[:,0], y=X_tsne[:,1], color=labels, opacity=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Sample Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoded_space_dim == 10:\n",
    "    # Generate a custom sample\n",
    "    custom_encoded_sample = [-12,-28,-30,-5,-31,6,7,8,9,10]\n",
    "    encoded_value = torch.tensor(custom_encoded_sample).float().unsqueeze(0).to(device)\n",
    "\n",
    "    # Decode sample\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        generated_img  = decoder(encoded_value)\n",
    "\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(generated_img.squeeze().cpu().numpy(), cmap='gist_gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#........................................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "# 5) Denoising Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(image, noise_factor):\n",
    "    \n",
    "    # torch.randn returns random values from a normal with mean 0 and variance 1 -> Gaussian noise!\n",
    "    noisy_img = image + noise_factor * torch.randn(image.shape)\n",
    "    #clip the image\n",
    "    noisy_img = np.clip(noisy_img, 0., 1.)\n",
    "    \n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1) Plot some Corrupted images and Recostruction with the normal ConvAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_imgs, rec_imgs  = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    imgc = test_dataset[0][0].unsqueeze(0)\n",
    "    corr_imgs.append(gaussian_noise(imgc, 0.1*i))\n",
    "\n",
    "for i in range(len(corr_imgs)):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = corr_imgs[i].to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Append the network output and the original image to the lists\n",
    "        rec_imgs.append(decoded_data.cpu())\n",
    "\n",
    "        \n",
    "# plot the corrupted input image and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "# input images on top row, reconstructions on bottom\n",
    "for corr_imgs, row in zip([corr_imgs, rec_imgs], axes):\n",
    "    for img, ax in zip(corr_imgs, row):\n",
    "        \n",
    "        ax.imshow(img.squeeze().cpu().numpy(), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) Train the Denoise AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class noise(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):\n",
    "        noise_factor=0.1*3\n",
    "        noisy_img = image + noise_factor * torch.randn(image.shape)\n",
    "        #clip the image\n",
    "        noisy_img = np.clip(noisy_img, 0., 1.)\n",
    "\n",
    "        return (image,noisy_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IN TRAIN TRASFORM \n",
    "train_transform_noise = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    noise(),\n",
    "])\n",
    "test_transform_noise = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    noise(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_noise = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset_noise  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "# Set the train transform\n",
    "train_dataset_noise.transform = train_transform_noise\n",
    "# Set the test transform\n",
    "test_dataset_noise.transform = test_transform_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define train dataloader\n",
    "train_dataloader_noise = DataLoader(train_dataset_noise, batch_size=256, shuffle=True)\n",
    "### Define test dataloader\n",
    "test_dataloader_noise = DataLoader(test_dataset_noise, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the transformation works\n",
    "for image in test_dataloader_noise:\n",
    "    \n",
    "    plt.imshow(image[0][0][0][0],cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    plt.imshow(image[0][1][0][0],cmap='gray')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    break\n",
    "\n",
    "img=test_dataset_noise[0][0][1].unsqueeze(0).to(device)\n",
    "\n",
    "plt.imshow(img.cpu().squeeze().numpy(),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer,noise=False):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    \n",
    "    \n",
    "    for image_batch, _ in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image= image_batch[0].to(device)\n",
    "        \n",
    "        noisy=image\n",
    "            \n",
    "        if noise: \n",
    "            noisy=image_batch[1].to(device)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Encode data\n",
    "        encoded_data = encoder(noisy)\n",
    "        \n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        \n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print batch loss\n",
    "        #print('\\t partial train loss (single batch): %f' % (loss.data))\n",
    "        \n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing function\n",
    "def test_epoch(encoder, decoder, device, dataloader, loss_fn,noise=False):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        \n",
    "        \n",
    "        \n",
    "        for image_batch, _ in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image= image_batch[0].to(device)\n",
    "        \n",
    "            noisy=image\n",
    "            \n",
    "            if noise: \n",
    "                noisy=image_batch[1].to(device)\n",
    "                \n",
    "            # Encode data\n",
    "            encoded_data = encoder(noisy)\n",
    "            \n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            \n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image.cpu())\n",
    "            \n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training cycle\n",
    "def training_cycle(num_epochs,early_stopping,encoder,decoder,loss_fn,optim,train_dataloader,device,test_dataset,test_dataloader):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []\n",
    "\n",
    "    max_early=float(\"-inf\")\n",
    "    idx_early=-1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        #print('\\t EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "\n",
    "        ### Training (use the training function)\n",
    "        train_loss=train_epoch(\n",
    "            encoder=encoder, \n",
    "            decoder=decoder, \n",
    "            device=device, \n",
    "            dataloader=train_dataloader, \n",
    "            loss_fn=loss_fn, \n",
    "            optimizer=optim,\n",
    "            noise=True)\n",
    "        train_loss_log.append(train_loss)\n",
    "        print('\\t TRAIN - EPOCH %d/%d - loss: %f' % (epoch + 1, num_epochs, train_loss))\n",
    "\n",
    "        ### Validation  (use the testing function)\n",
    "        val_loss = test_epoch(\n",
    "            encoder=encoder, \n",
    "            decoder=decoder, \n",
    "            device=device, \n",
    "            dataloader=test_dataloader, \n",
    "            loss_fn=loss_fn,\n",
    "            noise=True)\n",
    "        val_loss_log.append(val_loss)\n",
    "        print('\\t VALIDATION - EPOCH %d/%d - loss: %f' % (epoch + 1, num_epochs, val_loss))\n",
    "\n",
    "        ### Plot progress\n",
    "        # Get the output of a specific image (the test image at index 0 in this case)\n",
    "        img = test_dataset_noise[0][0][1].unsqueeze(0).to(device)\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "        with torch.no_grad():\n",
    "            rec_img  = decoder(encoder(img))\n",
    "        # Plot the reconstructed image\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "        axs[0].imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "        axs[0].set_title('Original image')\n",
    "        axs[1].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "        axs[1].set_title('Reconstructed image (EPOCH %d)' % (epoch + 1))\n",
    "        plt.tight_layout()\n",
    "        plt.pause(0.1)\n",
    "        # Save figures\n",
    "        os.makedirs('autoencoder_progress_%d_features' % encoded_space_dim, exist_ok=True)\n",
    "        fig.savefig('autoencoder_progress_%d_features/epoch_%d.jpg' % (encoded_space_dim, epoch + 1))\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "        # Save network parameters\n",
    "        torch.save(encoder.state_dict(), 'encoder_params.pth')\n",
    "        torch.save(decoder.state_dict(), 'decoder_params.pth')\n",
    "        torch.save(optim.state_dict(), 'optim_params.pth')\n",
    "\n",
    "\n",
    "        #Early stopping:\n",
    "        if idx_early==-1:\n",
    "            idx_early=epoch\n",
    "            max_early=val_loss\n",
    "        elif round(float(val_loss),3)<round(float(max_early),3):\n",
    "            idx_early=epoch\n",
    "            max_early=val_loss\n",
    "            \n",
    "        elif epoch-idx_early>=early_stopping:\n",
    "            print(\"STOPPED BY EARLY STOPPYNG\")\n",
    "            break\n",
    "    \n",
    "    return (train_loss_log,val_loss_log)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain the best model\n",
    "\"\"\"if best_hyper:\n",
    "    encoded_space_dim,conv1,conv2,conv3,fc,lr,l2=best_hyper\n",
    "    print(\"Training:\",best_hyper)\"\"\"\n",
    "\n",
    "encoded_space_dim = 10\n",
    "num_epochs=50\n",
    "early_stopping=5\n",
    "conv1=8\n",
    "conv2=16\n",
    "conv3=32\n",
    "fc=64\n",
    "lr=1e-3\n",
    "l2=1e-5\n",
    "drop=0\n",
    "\n",
    "### Initialize the two networks\n",
    "encoder = Encoder(encoded_space_dim=encoded_space_dim,dropout=drop, conv1=conv1,conv2=conv2,conv3=conv3,fc=fc)\n",
    "decoder = Decoder(encoded_space_dim=encoded_space_dim,dropout=drop, conv1=conv1,conv2=conv2,conv3=conv3,fc=fc)\n",
    "\n",
    "# Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=l2)\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "    \n",
    "    \n",
    "train_loss_log,val_loss_log=training_cycle(num_epochs,\n",
    "                                           early_stopping,\n",
    "                                           encoder,\n",
    "                                           decoder,\n",
    "                                           loss_fn,\n",
    "                                           optim,\n",
    "                                           train_dataloader_noise,\n",
    "                                           device,\n",
    "                                           test_dataset_noise,\n",
    "                                           test_dataloader_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses of the best model\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogy(train_loss_log, label='Train loss')\n",
    "plt.semilogy(val_loss_log, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=train_loss_log[-1]\n",
    "val_loss=val_loss_log[-1]\n",
    "print(\"Train Loss:\\t\",round(float(train_loss),3))\n",
    "print(\"Val Loss:\\t\",round(float(val_loss),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3) Plot some Corrupted images and Recostruction with the Denoise ConvAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_imgs, rec_imgs  = [], []\n",
    "\n",
    "for i in range(10):\n",
    "    imgc = test_dataset[0][0].unsqueeze(0)\n",
    "    corr_imgs.append(gaussian_noise(imgc, 0.1*i))\n",
    "\n",
    "for i in range(len(corr_imgs)):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = corr_imgs[i].to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Append the network output and the original image to the lists\n",
    "        rec_imgs.append(decoded_data.cpu())\n",
    "\n",
    "        \n",
    "# plot the corrupted input image and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "# input images on top row, reconstructions on bottom\n",
    "for corr_imgs, row in zip([corr_imgs, rec_imgs], axes):\n",
    "    for img, ax in zip(corr_imgs, row):\n",
    "        \n",
    "        ax.imshow(img.squeeze().cpu().numpy(), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "# 6) Supervised Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputLayer = nn.Linear(encoded_space_dim, 10)\n",
    "outputLayer = outputLayer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_loss_log = []\n",
    "val_loss_log = []\n",
    "\n",
    "max_early=float(\"-inf\")\n",
    "idx_early=-1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #print('\\t EPOCH %d/%d' % (epoch + 1, num_epochs))\n",
    "\n",
    "    ### Training (use the training function)\n",
    "    train_loss=train_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=train_dataloader, \n",
    "        loss_fn=loss_fn, \n",
    "        optimizer=optim)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    train_loss_log.append(train_loss)\n",
    "    print('\\t TRAIN - EPOCH %d/%d - loss: %f' % (epoch + 1, num_epochs, train_loss))\n",
    "\n",
    "    ### Validation  (use the testing function)\n",
    "    val_loss = test_epoch(\n",
    "        encoder=encoder, \n",
    "        decoder=decoder, \n",
    "        device=device, \n",
    "        dataloader=test_dataloader, \n",
    "        loss_fn=loss_fn)\n",
    "    val_loss_log.append(val_loss)\n",
    "    print('\\t VALIDATION - EPOCH %d/%d - loss: %f' % (epoch + 1, num_epochs, val_loss))\n",
    "\n",
    "    ### Plot progress\n",
    "    # Get the output of a specific image (the test image at index 0 in this case)\n",
    "    img = test_dataset_noise[0][0][1].unsqueeze(0).to(device)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        rec_img  = decoder(encoder(img))\n",
    "    # Plot the reconstructed image\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "    axs[0].imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[0].set_title('Original image')\n",
    "    axs[1].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[1].set_title('Reconstructed image (EPOCH %d)' % (epoch + 1))\n",
    "    plt.tight_layout()\n",
    "    plt.pause(0.1)\n",
    "    # Save figures\n",
    "    os.makedirs('autoencoder_progress_%d_features' % encoded_space_dim, exist_ok=True)\n",
    "    fig.savefig('autoencoder_progress_%d_features/epoch_%d.jpg' % (encoded_space_dim, epoch + 1))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Save network parameters\n",
    "    torch.save(encoder.state_dict(), 'encoder_params.pth')\n",
    "    torch.save(decoder.state_dict(), 'decoder_params.pth')\n",
    "    torch.save(optim.state_dict(), 'optim_params.pth')\n",
    "\n",
    "\n",
    "    #Early stopping:\n",
    "    if idx_early==-1:\n",
    "        idx_early=epoch\n",
    "        max_early=val_loss\n",
    "    elif round(float(val_loss),3)<round(float(max_early),3):\n",
    "        idx_early=epoch\n",
    "        max_early=val_loss\n",
    "\n",
    "    elif epoch-idx_early>=early_stopping:\n",
    "        print(\"STOPPED BY EARLY STOPPYNG\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "---\n",
    "# 7) Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses of the best model\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.semilogy(train_loss_log, label='Train loss')\n",
    "plt.semilogy(val_loss_log, label='Validation loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss=train_loss_log[-1]\n",
    "val_loss=val_loss_log[-1]\n",
    "print(\"Train Loss:\\t\",round(float(train_loss),3))\n",
    "print(\"Val Loss:\\t\",round(float(val_loss),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "# build model\n",
    "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)\n",
    "if torch.cuda.is_available():\n",
    "    vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(vae.parameters())\n",
    "# return reconstruction error + KL divergence losses\n",
    "def loss_function(recon_x, x, mu, log_var):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    vae.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_dataloader):\n",
    "        data = data.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        recon_batch, mu, log_var = vae(data)\n",
    "        loss = loss_function(recon_batch, data, mu, log_var)\n",
    "        \n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_dataloader.dataset),\n",
    "                100. * batch_idx / len(train_dataloader), loss.item() / len(data)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(epoch, train_loss / len(train_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    vae.eval()\n",
    "    test_loss= 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_dataloader:\n",
    "            data = data.cuda()\n",
    "            recon, mu, log_var = vae(data)\n",
    "            \n",
    "            # sum up batch loss\n",
    "            test_loss += loss_function(recon, data, mu, log_var).item()\n",
    "        \n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 51):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.?) Generate some samples from the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"number_of_samples=5\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(number_of_samples, 2).cuda()\n",
    "    sample = vae.decoder(z).cuda()\n",
    "\n",
    "for i in range(number_of_samples):\n",
    "    plt.imshow(sample.view(number_of_samples, 1, 28, 28)[i].cpu().squeeze().numpy(),cmap='gray')\n",
    "    plt.show()\"\"\"\n",
    "\n",
    "\n",
    "### Plot some sample\n",
    "fig, axs = plt.subplots(5, 5, figsize=(8,8))\n",
    "for ax in axs.flatten():\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(1, 2).cuda()\n",
    "        sample = vae.decoder(z).cuda()\n",
    "    sample=sample.view(1, 1, 28, 28)[0].cpu().squeeze().numpy()\n",
    "    \n",
    "    ax.imshow(sample, cmap='gray')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
