{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load from CSV\n",
    "train_dataset = pd.read_csv('regression_dataset/train_data.csv').values\n",
    "test_dataset = pd.read_csv('regression_dataset/test_data.csv').values\n",
    "\n",
    "#Prepare X_train, y_train, X_test, y_test\n",
    "X_train=train_dataset[:,0]\n",
    "y_train=train_dataset[:,1]\n",
    "\n",
    "X_test=test_dataset[:,0]\n",
    "y_test=test_dataset[:,1]\n",
    "\n",
    "#convert to Pytorch tensor\n",
    "X_train=np.expand_dims(X_train, axis=1)\n",
    "y_train=np.expand_dims(y_train, axis=1)\n",
    "X_train=torch.from_numpy(X_train).float()\n",
    "y_train=torch.from_numpy(y_train).float()\n",
    "\n",
    "X_test=np.expand_dims(X_test, axis=1)\n",
    "y_test=np.expand_dims(y_test, axis=1)\n",
    "X_test=torch.from_numpy(X_test).float()\n",
    "y_test=torch.from_numpy(y_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicRegNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, Ni, Nh1, Nh2, No):\n",
    "        \"\"\"\n",
    "        Ni - Input size\n",
    "        Nh1 - Neurons in the 1st hidden layer\n",
    "        Nh2 - Neurons in the 2nd hidden layer\n",
    "        No - Output size\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=Ni, out_features=Nh1)\n",
    "        self.fc2 = nn.Linear(in_features=Nh1, out_features=Nh2)\n",
    "        self.out = nn.Linear(in_features=Nh2, out_features=No)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.relu= nn.ReLU()\n",
    "        \n",
    "        self.name=\"BasicRegNet\"\n",
    "\n",
    "        print('Network initialized')\n",
    "        \n",
    "    def forward(self, x, additional_out=False):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Training device: {device}\")\n",
    "\n",
    "# Define the loss function\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "\n",
    "from skorch.callbacks import EarlyStopping\n",
    "\n",
    "my_early = EarlyStopping(\n",
    "    monitor='valid_loss',\n",
    "    patience=500,\n",
    "    threshold=0.0001,\n",
    "    threshold_mode='rel',\n",
    "    lower_is_better=True)\n",
    "\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "net = NeuralNetRegressor(\n",
    "    module=BasicRegNet,\n",
    "    module__Ni= 1,\n",
    "    module__Nh1 = 32,\n",
    "    module__Nh2 = 32,\n",
    "    module__No = 1,\n",
    "    max_epochs=2000,\n",
    "    \n",
    "    device=device,  # uncomment this to train with CUDA\n",
    "    optimizer = optim.Adam,\n",
    "    optimizer__lr=0.001,\n",
    "    optimizer__weight_decay=1e-5, #L2 norm\n",
    "    #criterion=nn.MSELoss() #used by default\n",
    "    callbacks = [my_early],\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2) Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'module__Nh1': [8,16,32,48],\n",
    "    'module__Nh2': [8,16,32,48],\n",
    "    'max_epochs': [1500],\n",
    "    'optimizer__lr':[0.1, 0.01, 0.001],\n",
    "    'optimizer__weight_decay':[1e-3,1e-4,1e-5] #L2 norm,\n",
    "}\n",
    "params = {\n",
    "    'module__Nh1': [8,48],\n",
    "    'module__Nh2': [8,48],\n",
    "    'max_epochs': [1500],\n",
    "    'optimizer__lr':[0.01, 0.001],\n",
    "    'optimizer__weight_decay':[1e-4,1e-5] #L2 norm,\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=True, cv=3, scoring=\"neg_mean_squared_error\",verbose=10)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net=gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3) Normal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4) Plot Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "save_name=datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "\n",
    "# get train losses from all epochs, a list of floats\n",
    "history = net.history\n",
    "train_loss_log=history[:, 'train_loss']\n",
    "val_loss_log=history[:, 'valid_loss']\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(train_loss_log)\n",
    "plt.plot(val_loss_log)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['Train loss', 'Validation loss'], loc='upper right')\n",
    "plt.savefig(\"models/\"+save_name+\"_Losses\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net.predict(X_test)\n",
    "y_pred = torch.from_numpy(y_pred).float()\n",
    "\n",
    "test_loss = loss_function(y_pred, y_test)\n",
    "print(f\"TEST LOSS: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipped_lists = zip(X_test, y_pred)\n",
    "sorted_pairs = sorted(zipped_lists)\n",
    "\n",
    "tuples = zip(*sorted_pairs)\n",
    "X, y = [ list(tuple) for tuple in  tuples]\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(X_test, y_test, color='r', ls='', marker='.')\n",
    "plt.plot(X, y, color='g', ls='--')\n",
    "plt.title('Test points vs Predicted Points')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid()\n",
    "plt.legend(['Test data points', 'Predictions'], loc='upper left')\n",
    "plt.savefig(\"models/\"+save_name+\"_Predictions\", dpi=400)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Loss\n",
    "train_loss=train_loss_log[-1]\n",
    "\n",
    "#Val loss\n",
    "val_loss=val_loss_log[-1]\n",
    "\n",
    "print(\"Train Loss:\\t\",round(train_loss,3))\n",
    "print(\"Val Loss:\\t\",round(val_loss,3))\n",
    "print(\"Test Loss:\\t\",round(float(test_loss),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the whole model\n",
    "import pickle\n",
    "with open(\"models/\"+save_name+\".pkl\", 'wb') as f:\n",
    "    pickle.dump(net, f)\n",
    "    \n",
    "#Load the model\n",
    "#with open(file_name, 'rb') as f:\n",
    "#    new_net = pickle.load(f)\n",
    "\n",
    "#Save Metrics to File\n",
    "f = open(\"models/\"+save_name+\"_Metrics.txt\", \"a\")\n",
    "f.write('Train loss:\\t'+ str(round(train_loss,3))+ \"\\n\")\n",
    "f.write('Val loss:\\t'+ str(round(val_loss,3))+ \"\\n\")\n",
    "f.write('Test loss:\\t'+ str(round(float(test_loss),3))+ \"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Network Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1) Weights histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access network parameters\n",
    "my_best_net = net.module_\n",
    "\n",
    "#First hidden Layer\n",
    "h1_w = my_best_net.fc1.weight.data.cpu().numpy()\n",
    "h1_b = my_best_net.fc1.bias.data.cpu().numpy()\n",
    "\n",
    "#Second hidden Layer\n",
    "h2_w = my_best_net.fc2.weight.data.cpu().numpy()\n",
    "h2_b = my_best_net.fc2.bias.data.cpu().numpy()\n",
    "\n",
    "# Output layer\n",
    "out_w = my_best_net.out.weight.data.cpu().numpy()\n",
    "out_b = my_best_net.out.bias.data.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights histogram\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12,8))\n",
    "axs[0].hist(h1_w.flatten(), 50)\n",
    "axs[0].set_title('First hidden layer weights')\n",
    "axs[1].hist(h2_w.flatten(), 50)\n",
    "axs[1].set_title('Second hidden layer weights')\n",
    "axs[2].hist(out_w.flatten(), 50)\n",
    "axs[2].set_title('Output layer weights')\n",
    "[ax.grid() for ax in axs]\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"models/\"+save_name+\"_Weights-histogram\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2) Analyze activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(layer, input, output):\n",
    "    global activation\n",
    "    activation = torch.sigmoid(output)\n",
    "    \n",
    "### Register hook\n",
    "net=my_best_net\n",
    "hook_handle = net.fc2.register_forward_hook(get_activation)\n",
    "\n",
    "### Analyze activations\n",
    "net = net.to(device)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    x1 = torch.tensor([0.1]).float().to(device)\n",
    "    y1 = net(x1)\n",
    "    z1 = activation\n",
    "    x2 = torch.tensor([0.9]).float().to(device)\n",
    "    y2 = net(x2)\n",
    "    z2 = activation\n",
    "    x3 = torch.tensor([2.5]).float().to(device)\n",
    "    y3 = net(x3)\n",
    "    z3 = activation\n",
    "\n",
    "### Remove hook\n",
    "hook_handle.remove()\n",
    "\n",
    "### Plot activations\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12,6))\n",
    "axs[0].stem(z1.cpu().numpy(), use_line_collection=True)\n",
    "axs[0].set_title('Last layer activations for input x=%.2f' % x1)\n",
    "axs[1].stem(z2.cpu().numpy(), use_line_collection=True)\n",
    "axs[1].set_title('Last layer activations for input x=%.2f' % x2)\n",
    "axs[2].stem(z3.cpu().numpy(), use_line_collection=True)\n",
    "axs[2].set_title('Last layer activations for input x=%.2f' % x3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"models/\"+save_name+\"_Activations\", dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
